{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import atc_dataloader, atc_model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from atc_loss import PredictionLoss_COS_MSE, PredictionLoss_BOX_Wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_vector_to_integers(pred):\n",
    "    # get the max value, that will serve as reference - where is the max, there is supposed to be 1 (or other integer, depends...)\n",
    "    # for now, everything until 1.3 will be treated as 1, until 2.3 as two etc.\n",
    "    \n",
    "    # lambda to round function from the specific treshold defined in range [.0;1.0)\n",
    "    my_treshold = 0.3\n",
    "    tr = np.min([my_treshold, pred.max()*0.9])\n",
    "\n",
    "    myround = np.vectorize(lambda x, treshold=tr: np.floor(x) if x < (np.floor(x) + treshold) else np.ceil(x))\n",
    "\n",
    "    result = np.apply_along_axis(func1d=myround, axis=0,arr=pred)\n",
    "    return result\n",
    "    \n",
    "    \n",
    "def evaluate(model, data_loader, device, criterion):\n",
    "    \"\"\"\n",
    "    function used to evaluate the model, return loss and accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        total_ok = 0\n",
    "        temp_loss = []\n",
    "        for  _, batch_in_vectors, batch_out_vectors in data_loader:\n",
    "            pred = model(batch_in_vectors.to(device))\n",
    "            loss = criterion(pred, batch_out_vectors.to(device))\n",
    "            temp_loss.append(loss.item())\n",
    "            \n",
    "            y_true.extend(batch_out_vectors)\n",
    "            \n",
    "            y_pred.extend(pred)\n",
    "            \n",
    "            print(len(y_true))\n",
    "            print(len(y_pred))\n",
    "            # print(y_true)\n",
    "            # print(y_pred)\n",
    "            break\n",
    "        \n",
    "        mean_loss = np.mean(temp_loss)\n",
    "        \n",
    "        print(total_ok, total_ok/len(data_train))\n",
    "    return mean_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, dataloader, criterion, optimizer, epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    loss_overall = []\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = []\n",
    "        # Wrap dataloader with tqdm for progress visualization\n",
    "        \n",
    "        for _, batch_in_vectors, batch_out_vectors in tqdm(dataloader, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch'):\n",
    "            # Convert data to tensors and move to the correct device\n",
    "            batch_in_vectors = torch.tensor(batch_in_vectors, dtype=torch.float32).to(device)\n",
    "            batch_out_vectors = torch.tensor(batch_out_vectors, dtype=torch.float32).to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_in_vectors)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, batch_out_vectors)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "        # Print loss for the current epoch\n",
    "        avg_loss = np.mean(epoch_loss)\n",
    "        loss_overall.append(avg_loss) # add it to the loss over all epochs\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # plot graph\n",
    "    plt.plot(np.arange(0,epochs,1),loss_overall)\n",
    "    plt.title('Loss function')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "TRAIN_IN=\"data/train_in.csv\"\n",
    "TRAIN_OUT=\"data/train_out.csv\"\n",
    "\n",
    "data_train = atc_dataloader.ATCDataset(TRAIN_IN, TRAIN_OUT)\n",
    "\n",
    "TEST_IN=\"data/test_in.csv\"\n",
    "TEST_OUT=\"data/test_out.csv\"\n",
    "\n",
    "data_test = atc_dataloader.ATCDataset(TEST_IN, TEST_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = atc_model.BaseNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.005)\n",
    "dl_train = DataLoader(data_train, batch_size=32, shuffle=True)  \n",
    "criterion = PredictionLoss_COS_MSE().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_test = DataLoader(data_test, batch_size=32, shuffle=False)\n",
    "criterion = PredictionLoss_COS_MSE()\n",
    "evaluate(model, dl_test, device, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vals = [0.1818,0.1689,0.1597,0.1411,0.0732,0.0624,0.0598,0.0585,0.0574,0.0568]\n",
    "plt.plot(np.arange(0,10,1),loss_vals)\n",
    "# regex to get number after word loss\n",
    "import re \n",
    "text = \"\"\"\n",
    "Epoch 1/10: 100%|██████████| 3768/3768 [04:46<00:00, 13.14batch/s]\n",
    "Epoch [1/10], Loss: 0.1818\n",
    "Epoch 2/10: 100%|██████████| 3768/3768 [04:44<00:00, 13.23batch/s]\n",
    "Epoch [2/10], Loss: 0.1689\n",
    "Epoch 3/10: 100%|██████████| 3768/3768 [04:44<00:00, 13.23batch/s]\n",
    "Epoch [3/10], Loss: 0.1597\n",
    "Epoch 4/10: 100%|██████████| 3768/3768 [16:21<00:00,  3.84batch/s]    \n",
    "Epoch [4/10], Loss: 0.1411\n",
    "Epoch 5/10: 100%|██████████| 3768/3768 [04:48<00:00, 13.05batch/s]\n",
    "Epoch [5/10], Loss: 0.0732\n",
    "Epoch 6/10: 100%|██████████| 3768/3768 [04:44<00:00, 13.23batch/s]\n",
    "Epoch [6/10], Loss: 0.0624\n",
    "Epoch 7/10: 100%|██████████| 3768/3768 [04:41<00:00, 13.40batch/s]\n",
    "Epoch [7/10], Loss: 0.0598\n",
    "Epoch 8/10: 100%|██████████| 3768/3768 [04:43<00:00, 13.28batch/s]\n",
    "Epoch [8/10], Loss: 0.0585\n",
    "Epoch 9/10: 100%|██████████| 3768/3768 [8:23:13<00:00,  8.01s/batch]       \n",
    "Epoch [9/10], Loss: 0.0574\n",
    "Epoch 10/10: 100%|██████████| 3768/3768 [04:45<00:00, 13.18batch/s]\n",
    "Epoch [10/10], Loss: 0.0568\n",
    "\"\"\"\n",
    "pattern = r'(?<=Loss:)\\s*\\d+\\.\\d*'\n",
    "matches = re.findall(pattern, text)\n",
    "matches = np.array(matches).astype(float)\n",
    "print(matches)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, device, dl_train, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), 'models/model_basenn2.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with already trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights to the model\n",
    "model = atc_model.BaseNN().to(device)\n",
    "model.load_state_dict(torch.load('models/model_basenn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2\n",
    "target = data_train.__getitem__(idx)[2]\n",
    "pred = model(data_train.__getitem__(idx)[1]) \n",
    "print(target)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the prediction loss\n",
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "mse = nn.MSELoss()\n",
    "    \n",
    "# Define weights for functions for Cos and MSE.\n",
    "w1 = 5\n",
    "w2 = 10\n",
    "cc = cos(torch.tensor([.1,3,4]), torch.tensor([.1,3,4]))\n",
    "# cc = cos(torch.cumsum(pred, dim=-1), torch.cumsum(target, dim=-1))\n",
    "print(cc)\n",
    "# Apply cumulative sum to both tensors and calculate loss.\n",
    "cos_sim = torch.abs(cos(torch.cumsum(pred, dim=-1), torch.cumsum(target, dim=-1))).mean()\n",
    "mse_loss = mse(torch.cumsum(pred, dim=-1), torch.cumsum(target, dim=-1))\n",
    "loss = (w1 * mse_loss) / (w2 * cos_sim)\n",
    "# penalty for the number of places, where prediction misses the zero in target\n",
    "# let say where the \n",
    "non_zero_indices_target = np.count_nonzero(target)\n",
    "max_value_pred = torch.max(pred)\n",
    "# now everywhere the value goes up the half of max_value_pred penalty is count  --- this is self defined rule\n",
    "\n",
    "print(non_zero_indices_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ok = 0\n",
    "for d in data_train:\n",
    "    if np.argmax(d[2]) == torch.argmax(model(d[1])):\n",
    "        total_ok += 1\n",
    "print(total_ok, total_ok/len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=np.sum([0.0807, 0.0806, 0.0767, 0.0896, 0.0916, 0.0810, 0.0730, 0.0753, 0.0657,\n",
    "        0.0643, 0.0469, 0.0318, 0.0343, 0.0303, 0.0034, 0.0037, 0.0001, 0.0095])\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
