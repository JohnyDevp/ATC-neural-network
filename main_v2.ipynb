{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import atc_dataloader, atc_model\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from atc_loss import PredictionLoss_COS_MSE, PredictionLoss_BOX_Wise\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_vector_to_integers(pred):\n",
    "    # //////////////////////////////////////////////////////////\n",
    "    # CURRENTLY NOT USED\n",
    "    # //////////////////////////////////////////////////////////\n",
    "    # get the max value, that will serve as reference - where is the max, there is supposed to be 1 (or other integer, depends...)\n",
    "    # for now, everything until 1.3 will be treated as 1, until 2.3 as two etc.\n",
    "    \n",
    "    # lambda to round function from the specific treshold defined in range [.0;1.0)\n",
    "    my_treshold = 0.3\n",
    "    tr = np.min([my_treshold, pred.max()*0.9])\n",
    "\n",
    "    myround = np.vectorize(lambda x, treshold=tr: np.floor(x) if x < (np.floor(x) + treshold) else np.ceil(x))\n",
    "\n",
    "    result = np.apply_along_axis(func1d=myround, axis=0,arr=pred)\n",
    "    return result\n",
    "\n",
    "def evaluate(model, data_loader, device, criterion):\n",
    "    \"\"\"\n",
    "    function used to evaluate the model, return loss and accuracy\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = []\n",
    "    with torch.no_grad():\n",
    "        for  _, batch_in_vectors, batch_out_vectors in data_loader:\n",
    "            pred = model(batch_in_vectors.to(device))\n",
    "            loss = criterion(pred, batch_out_vectors.to(device))\n",
    "            test_loss.append(loss.item())\n",
    "    \n",
    "    return np.mean(test_loss)\n",
    "\n",
    "# def evaluate_real_similarity(dl_test,model,device):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.  ]\n",
      " [0.21 0.   0.  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def real_vector_similarity(vec1, vec2, tolerance=0.1):\n",
    "    # Convert to numpy arrays for element-wise comparison\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    \n",
    "    # Compute the absolute difference between corresponding elements\n",
    "    difference = np.abs(vec1 - vec2)\n",
    "    print(difference)\n",
    "    # Check if all differences are within the given tolerance\n",
    "    return np.all(difference <= tolerance)\n",
    "\n",
    "real_vector_similarity([[1.0, 2.0, 3.0],[5.09, 6.0, 7.0]], [[1.0, 2.0, 3.0],[5.3, 6.0, 7.0]], tolerance=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device, train_dl, test_dl, criterion, optimizer, epochs=10, save_model_last_epoch=True, model_path='.'):\n",
    "    \n",
    "    # loss that will be calculated after each epoch for both test and train set \n",
    "    train_loss_overall = []\n",
    "    test_loss_overall = [] \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = []\n",
    "        model.train()  # Set the model to training mode\n",
    "        \n",
    "        # Wrap dataloader with tqdm for progress visualization\n",
    "        for _, batch_in_vectors, batch_out_vectors in tqdm(train_dl, desc=f'Epoch {epoch + 1}/{epochs}', unit='batch'):\n",
    "            # Convert data to tensors and move to the correct device\n",
    "            batch_in_vectors = torch.tensor(batch_in_vectors, dtype=torch.float32, requires_grad=True).to(device)\n",
    "            batch_out_vectors = torch.tensor(batch_out_vectors, dtype=torch.float32).to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_in_vectors)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, batch_out_vectors)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate loss\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "        if (epoch % 20 == 0):\n",
    "            torch.save(model.state_dict(), f'models/model_betternn_epoch_{epoch}.pth')\n",
    "        \n",
    "        # start evaluation and append test loss\n",
    "        tmp_test_loss = evaluate(model, test_dl, device, criterion)\n",
    "        test_loss_overall.append(tmp_test_loss)\n",
    "        \n",
    "        # Calculate average train loss for the epoch\n",
    "        avg_train_loss = np.mean(epoch_loss)\n",
    "        train_loss_overall.append(avg_train_loss) # add it to the loss over all epochs\n",
    "        \n",
    "        # Print loss (both train and test) for the current epoch\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train loss: {avg_train_loss:.4f}, Test loss: {tmp_test_loss:.4f}\")\n",
    "\n",
    "    # ====================================\n",
    "    # AFTER TRAIN ========================\n",
    "    # ====================================\n",
    "    \n",
    "    # save the model after the last epoch if set\n",
    "    # if (save_model_last_epoch):\n",
    "    #     torch.save(model.state_dict(), f'{model_path}/model_last_epoch_{time.time_ns()}.pth')\n",
    "        \n",
    "    # print overall loss\n",
    "    print('Overall train loss: ', train_loss_overall)\n",
    "    print('Overall test loss: ', test_loss_overall)\n",
    "    # plot graph\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0,epochs,1),train_loss_overall, label='Train loss') # train loss over all epochs\n",
    "    plt.plot(np.arange(0,epochs,1),test_loss_overall, label='Test loss') # test loss over all epochs\n",
    "    plt.title('Loss function')\n",
    "    plt.show()\n",
    "    \n",
    "    return train_loss_overall, test_loss_overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "TRAIN_IN=\"data/train_in.csv\"\n",
    "TRAIN_OUT=\"data/train_out.csv\"\n",
    "# TRAIN_IN='data/sample_in.csv'\n",
    "# TRAIN_OUT='data/sample_out.csv'\n",
    "data_train = atc_dataloader.ATCDataset_v2(TRAIN_IN, TRAIN_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IN=\"data/test_in.csv\"\n",
    "TEST_OUT=\"data/test_out.csv\"\n",
    "# TEST_IN='data/sample_in.csv'\n",
    "# TEST_OUT='data/sample_out.csv'\n",
    "data_test = atc_dataloader.ATCDataset_v2(TEST_IN, TEST_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = atc_model.BetterNN().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, weight_decay=0.005)\n",
    "criterion = PredictionLoss_BOX_Wise().to(device)\n",
    "dl_train = DataLoader(data_train, batch_size=32, shuffle=True)  \n",
    "dl_test = DataLoader(data_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, test_loss = train_model(model, device, dl_train, dl_test, criterion, optimizer, epochs=100)\n",
    "torch.save(model.state_dict(), f'models/model_basenn{time.time_ns()}.pth') # it will be saved, ...but just in case (rly doesnt make much sense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train phase 2 (next 300 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_phase2, test_loss_phase2 = train_model(model, device, dl_train, dl_test, criterion, optimizer, epochs=300)\n",
    "torch.save(model.state_dict(), f'models/model_betternn_200epochs_{time.time_ns()}.pth') # it will be saved, ...but just in case (rly doesnt make much sense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_y_train = np.concatenate((train_loss, train_loss_phase2))\n",
    "loss_y_test = np.concatenate((test_loss, test_loss_phase2))\n",
    "loss_x = np.arange(0, len(loss_y_train), 1)\n",
    "# plot graph\n",
    "plt.figure()\n",
    "plt.plot(loss_x,loss_y_train, label='Train loss') # train loss over all epochs\n",
    "plt.plot(loss_x,loss_y_test, label='Test loss') # test loss over all epochs\n",
    "plt.title('Loss function')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
